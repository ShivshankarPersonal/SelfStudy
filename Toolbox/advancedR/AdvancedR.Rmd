---
title: "<strong>Advanced `R`</strong>"
author: "andrés castro araújo"
date: "`r format(Sys.Date(), '%b %d, %Y')`"
output: 
  html_document: 
    theme: lumen
    toc: yes
    toc_float: 
      collapsed: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = "", fig.align = "center")

# library(tidyverse)
# theme_set(theme_minimal(base_family = "Avenir", base_line_size = 0))

library(magrittr)
```


```{r results="asis", echo=FALSE}
cat('
<style>
blockquote {
    padding: 10px 20px;
    margin: 0 0 20px;
    font-size: 14px;
    color: #828282;
    border-left: 10px solid #EEE;
}
</style>
')
```

>All of this is taken from Hadley Wickham. [__Advanced R__](https://adv-r.hadley.nz). CRC Press, 2019.

****

## Introduction

Somethings about `R` are different from what you'd expect to see in other programming languages. 

- Copy-on-modify semantics, which makes sense once we really understand the difference between an object and its name.

- In `R`, _almost_ everything is a vector. And almost everything that happens is a _function call_.

- There are three subsetting operators, `[[`, `[`, and `$`, and all of them interact in different ways with different vector types.

- R has aspects of both functional and object-oriented (OO) programming languages.

FINISH THIS SECTION AFTERWARDS

## Copy-on-modify semantics

We’ll use the `lobstr` package to dig into the internal representation of R objects.

```{r}
library(lobstr)
```

Suppose we want to contain an object `x` that contains the values 1, 2, and 3.

```{r}
x <- c(1, 2, 3)
```

But this is _not_ an object with a name. R first creates a vector of values `c(1,2,3)` and then binds that object to a name `x`. 

>In other words, the object, or value, doesn’t have a name; it’s actually the name that has a value.

Thus, names are actually references to values. And if we now run `y <- x`, we don't get another copy of the value `c(1,2,3)`; instead, we get another binding to the existing object.

```{r, echo=FALSE, out.width="180px"}
knitr::include_graphics(
"https://d33wubrfki0l68.cloudfront.net/bdc72c04d3135f19fb3ab13731129eb84c9170af/f0ab9/diagrams/name-value/binding-2.png"
)
```

The `0x74b` refers to the object independently of its bindings. We can use `lobstr` to see that both `x` and `y` point to the same identifier. Note that these identifiers are long, and change every time you restart R.

```{r}
obj_addr(x)
y <- x
obj_addr(y)
```

Now suppose we modify `y`, but not `x`. 

```{r}
y[[2]] <- 100
```

R creates a new object `0xcd2`, which is basically the same as `0x74b` with one value change. Finally, the name `y` is rebound to that new object.

```{r, echo=FALSE, out.width="170px"}
knitr::include_graphics(
"https://d33wubrfki0l68.cloudfront.net/ef9f480effa2f1d0e401d1f94218d0cf118433c0/b56e9/diagrams/name-value/binding-3.png"
)
```

>This behaviour is called __copy-on-modify.__ Understanding it will radically improve your intuition about the performance of R code.

This, for example, explains why loops perform better when we feed them a vector of adequate size.

```{r}
output <- vector("integer", length = 3)
for (i in 1:5) {
  output[[i]] <- i
  print(obj_addr(output)) ## remains the same while vector is length = 3
}
```

__Lists__

The elements of a list point to values, they behave just like names. Instead of storing the values themselves, 

```{r}
l1 <- l2 <- list(1, 2, 3)
```

```{r, echo=FALSE, out.width="180px"}
knitr::include_graphics(
"https://d33wubrfki0l68.cloudfront.net/52bc0e3da3382cba957a9d83397b6c9200906ce2/c72aa/diagrams/name-value/l-modify-1.png"
)
```

```{r}
l2[[3]] <- 4
```

```{r, echo=FALSE, out.width="180px"}
knitr::include_graphics(
"https://d33wubrfki0l68.cloudfront.net/b844bb5a3443e1344299627f5760e2ae3a9885b5/e1c76/diagrams/name-value/l-modify-2.png"
)
```

>Like vectors, lists use copy-on-modify behaviour; the original list is left unchanged, and R creates a modified copy. This, however, is a __shallow copy__: the list object and its bindings are copied, but the values pointed to by the bindings are not.

We can use `lobstr::ref()` to see the values that are shared across both lists.

```{r}
lobstr::ref(l1, l2)
```

And because values are being shared, the size of lists is sometimes unintuitive. More generally, `obj_size(x)` + `obj_size(y)` will only equal `obj_size(x, y)`
if they share no values.

```{r}
x <- runif(1000)
y <- list(x, x, x)
ref(x, y)
obj_size(x) + obj_size(y)
obj_size(x, y)
```

__Data frames__

Data frames are lists of vectors, so copy-on-modify works very similar in this setting, except the following:

- "If you modify a column, only that column needs to be modified; the others will still point to their original references."

- "However, if you modify a row, every column is modified, which means every column must be copied."

****

>Note. The latests versions of R have a feature called ALTREP, short for __alternative representation__. It allows for R to represent some types of vectors very compactly. The place you are most likely to see this is with `:` because instead of storing every single number in the sequence, R just stores the first and last number.

```{r}
obj_size(c(1, 2, 3, 4, 5))
obj_size(1:5)
x <- 1:5000
obj_size(x)
x[[333]] <- 9 ## note the massive increase in size
obj_size(x) 
```

****

An important exception with regards to the copy-on-modify semantics occurs with `environments`, a special type of object that is always __modified on place__.

>This property is sometimes described as __reference semantics__ because when you modify an environment all existing bindings to that environment continue to have the same reference.

## Vectors

There are two types of vectors in R:

- __Atomic vectors__, of which there are six types: `logical`, `integer`, `double`, `character`, `complex`, and `raw.` Integer and double vectors are collectively known as _numeric_ vectors.

    You can determine the type of a vector with the `typeof()` function.

- __Lists__, which are sometimes called recursive vectors (because lists can contain other lists). Other times they're called generic vectors to emphasise their difference from atomic vectors.

The chief difference between atomic vectors and lists is that atomic vectors are _homogeneous_, while lists can be _heterogeneous._ There’s one other related object: `NULL`, which is often used to represent the absence of a vector (as opposed to `NA`, which is used to represent the absence of a value in a vector).

Most computations involving a missing value will return another missing value, with a couple of obvious exceptions:

```{r}
NA^0
NA | TRUE
NA & FALSE
```

___Attributes___

Every vector can have __attributes__ (i.e. a named list of arbitrary metadata). Two attributes are particularly important: _dimension_, which turns vectors into matrices and arrays; and _class_, which powers the S3 object system.

You can _name_ a vector in three ways:

```{r}
# When creating it: 
x <- c(a = 1, b = 2, c = 3)

# By assigning a character vector to names()
x <- 1:3
names(x) <- c("a", "b", "c")

# Inline, with setNames():
x <- setNames(1:3, c("a", "b", "c"))
```

```{r}
str(x)
```

Other attributes are set (or retrieved) with the `attr()` function,

```{r}
attr(x, "names") <- c("a", "b", "c")
attr(x, "arbitrary") <- rnorm(1)
str(x)
```

And we can extract all of them with the `attributes()` function.

```{r}
attr(x, "arbitrary")
attributes(x) ## returns a named list
```

__Dimensions__

Adding a `dim` attribute to a vector allows it to behave like a 2-dimensional matrix or a multi-dimensional array.

```{r}
x <- 1:20
dim(x) <- c(4, 5)
x
dim(x) <- c(2, 5, 2)
x
```

Note that many of the functions for working with vectors have generalisations for matrices and arrays:

```{r, echo=FALSE}
knitr::kable(
tibble::tibble(
  vector = c("`names()`", "`length()`", "`c()`", "", "`is.null(dim(x))`"),
  matrix = c("`rownames()`, `colnames()`", "`nrow()`, `ncol()`", "`rbind()`, `cbind()`", "`t()`", "`is.matrix()`"),
  array = c("`dimnames()`", "`dim()`", "`abind::abind()`", "`aperm()`", "`is.array()`"))
) %>% 
  kableExtra::kable_styling(full_width = FALSE, bootstrap_options = "bordered")
```

___S3 atomic vectors___

Having a __`class`__ attribute turns an object into an _S3 object_, which makes it behave differently from a regular vector when passed to a _generic function_.

Four types of important S3 vectors used in R:

- `factor` vectors, used to store categorical data. where values come Factors are built on top of an integer vector with two attributes: a "factor" `class`, which makes them behave differently from regular integer vectors; and "levels", which defines the set of allowed values.

    "Ordered factors" are a minor variation of factors (i.e. a < b < c).

- Dates (with day resolution), which are recorded in `Date` vectors. They're built on top of "double" vectors. They have a class “Date”, and no other attributes.

    The value of the double, represents the number of days since "1970-01-01" (also known as the Unix Epoch).
    
    ```{r}
    x <- 0
    class(x) <- "Date"
    x
    ```

- Date-times are much like dates, except that they also have second or sub-second resolution. These are also built on top of doubles, but they have a `POSIXct` class.

    >"POSIX" is short for Portable Operating System Interface, which is a family of cross-platform standards. "ct" standards for calendar time (the `time_t` type in C).

    ```{r}
    x <- as.POSIXct("1990-03-04 2:00", tz = "UTC")
    x
    attributes(x)
    attr(x, which = "tzone") <- "EST"
    x
    ```

    >The `tzone` attribute controls only how the date-time is formatted; it does not control the instant of time represented by the vector.
    
    EST stands for Eastern Daylight Time, whereas UTC stands for [Universal Time Coordinated](https://en.wikipedia.org/wiki/Coordinated_Universal_Time).

- Durations, which are stored in `difftime` vectors. They're built on top of doubles and have an additional units attribute that determines how to interpret the numeric value.

    ```{r}
    x - x
    class(x - x)
    as.difftime(1.5, units = "weeks")
    ```

___Lists___

Every element of a list can be of any type. Technically speaking, however, each element of list is really a reference (or a binding) to another object, which can be of any type.

>This makes them fundamentally different from atomic vectors.

You can turn a list into an atomic vector with `unlist()`. But the rules for the resulting type are complex and not well documented.

The most important S3 vectors that are built upon lists are data frames and tibbles. In both cases, the length of each of its vectors must be the same. 

```{r}
typeof(mtcars)
attributes(mtcars)
```

Tibbles, on the other hand, are provided by the [__`tibble`__](https://tibble.tidyverse.org/) package.

>A concise, and fun, way to summarise the main differences is that tibbles are lazy [they don't coerce their input (e.g. `stringsAsFactors = FALSE`)] and surly: they do less and complain more.

```{r}
library(tibble)
df <- tibble(x = 1:3, y = LETTERS[1:3])
typeof(df)
attributes(df)
```

But perhaps the biggest difference between data frames and tibbles is that the later are designed to disregard rownames.

```{r}
attributes(as_tibble(mtcars))
```

>There are three reasons why row names are undesirable:
>
>1. Metadata is data, so storing it in a different way to the rest of the data is fundamentally a bad idea. It also means that you need to learn a new set of tools to work with row names; you can’t use what you already know about manipulating columns.
>
>2. Row names are a poor abstraction for labelling rows because they only work when a row can be identified by a single string. This fails in many cases, for example when you want to identify a row by a non-character vector (e.g. a time point), or with multiple vectors (e.g. position, encoded by latitude and longitude).
>
>3. Row names must be unique, so any duplication of rows (e.g. from bootstrapping) will create new row names. If you want to match rows from before and after the transformation, you’ll need to perform complicated string surgery.
>
>For these reasons, tibbles do not support row names. Instead the tibble package provides tools to easily convert row names into a regular column with either `rownames_to_column()`, or the `rownames` argument in `as_tibble()`.

Finally, making use of _list-columns_ with tibbles is much easier.

>Since a data frame is a list of vectors, it is possible for a data frame to have a column that is a list. This is very useful because a list can contain any other object: this means you can put any object in a data frame. This allows you to keep related objects together in a row, no matter how complex the individual objects are.

```{r, error=TRUE}
df <- data.frame(x = 1:3)
df$y <- list(1:2, 1:3, 1:4)
df

data.frame(
  x = 1:3, 
  y = list(1:2, 1:3, 1:4)  ## This doesn't work!
)

tibble(
  x = 1:3, 
  y = list(1:2, 1:3, 1:4)
)

```

## Subsetting

>Subsetting is a natural complement to `str()`. While `str()` shows you all the pieces of any object (its structure), subsetting allows you to pull out the pieces that you’re interested in. 

R has three subsetting operators: `[`, `[[`, and `$`. The `[` operator lets you subset atomic vectors.

___Six ways to subset atomic vectors.___

```{r, error=TRUE}
## 1. Positive integers
letters[3:1]
letters[c(2, 2, 2)]
letters[c(1.9, 2.1, 2.8)] ## silently truncated to integers

## 2. Negative integers
letters[1:20 * -1]
letters[c(-1, 2)] ## can't mix!

## 3. Logical vectors
letters > "m"
letters[letters > "m"]

## 4. Nothing. Useful for matrices, data frames, and arrays
letters[]

## 5. Zero returns a zero-length vector. Usually not done on purpose
letters[0]
```

Finally, if the vector is _named_, you can use character vectors to return elements with matching names.

```{r}
## 6. Character vectors
(y <- setNames(1:4, letters[1:4]))
y["c"]
y[c("a", "a", "c", "a", "x")]
```

A final word of caution:

>Factors are not treated specially when subsetting. This means that subsetting will use the underlying integer vector, not the character levels. This is typically unexpected, so you should avoid subsetting with factors.

___Subsetting operators interact differently with different vector types (e.g., atomic vectors, lists, factors, matrices, and data frames)___

- Subsetting a list will work in the same way as subsetting atomic vectors. `[` always returns a list, whereas `[[` and `$` pull elements out of a list.

- The easiest way of subsetting matrices (2D) and arrays (>2D) is to supply a 1D index for each dimension separated by a comma.

    And because both matrices and arrays are just vectors with special a `dimension` attribute, you can always subset them with a single vector (i.e. treat them as if they were a 1D vector). 
    
    Note: Arrays in R are stored in column-major order.
    
- We can also subset matrices and arrays with a matrix (integer, logical, and character if named).

    For example:

    ```{r}
    x <- outer(1:4, 1:4, FUN = "+")
    x
    upper.tri(x)
    x[upper.tri(x)]
    ```

- Subsetting a data frame with a simple index makes it behave like a list (e.g. `df[1:2]` selects the first two columns).

    Subsetting a data frame with two indices makes it behave like a matrix (e.g. `df[1:3, ]` selects the first three rows).

    >By default, subsetting a matrix or data frame with a single number, a single name, or a logical vector containing a single `TRUE`, will simplify the returned output, i.e. it will return an object with lower dimensionality. To preserve the original dimensionality, you must use `drop = FALSE`.

    Tibbles have `drop = FALSE` by default.

>_Exercise. Implement your own function that extracts the diagonal entries from a matrix (it should behave like diag(x) where x is a matrix)._

```{r}
extract_diag <- function(x) {      # When subsetting with integer matrices,
  end <- min(nrow(x), ncol(x))     # each row specifies the location of one 
  return(x[cbind(1:end, 1:end)])   # value, and each column corresponds to a 
}                                  # dimension in the array.
```

___Selecting a single element___

The `[[` operator is used for extracting single items; `$`, on the other hand, is a shorthand operator: `x$y` is equivalent to `x[["y"]]`. These operators are mostly useful when working with lists, because while `[` returns a smaller list, `[[` will actually extract the content of that list.

```{r}
mtcars[["mpg"]]
identical(mtcars[["mpg"]], mtcars$mpg)
```

>Because `[[` can return only a single item, you must use it with either a single positive integer or a single string. If you use a vector with `[[`, it will subset recursively, i.e. `x[[c(1, 2)]]` is equivalent to `x[[1]][[2]]`. This is a quirky feature that few know about, so I recommend avoiding it in favour of `purrr::pluck()`.
>
>When the element is missing, `pluck()` always returns `NULL` (or the value of the .default argument) and `chuck()` always throws an error. The behaviour of `pluck()` makes it well suited for indexing into deeply nested data structures where the component you want may not exist (as is common when working with JSON data from web APIs). `pluck()` also allows you to mix integer and character indices, and provides an alternative default value if an item does not exist:

```{r, error=TRUE}
x <- list(
  a = list(1, 2, 3),
  b = list(3, 4, 5)
)

purrr::pluck(x, "a", 1)
purrr::pluck(x, "c", 1)
purrr::chuck(x, "c", 1)
purrr::pluck(x, "c", 1, .default = NA)
```

`$` is most commonly used to access variables in a data frame.

>One common mistake with `$` is to use it when you have the name of a column stored in a variable.

```{r}
var <- "mpg"
# Doesn't work - mtcars$var translated to mtcars[["var"]]
mtcars$var

# Instead use [[
mtcars[[var]]
```

Finally, `$` does left-to-right partial matching on regular data frames, which can be a frustrating source of errors. Tibbles, on the other hand, will never do partial matching.

___Subsetting and assignment___

>All subsetting operators can be combined with assignment to modify selected values of an input vector: this is called subassignment. The basic form is `x[i] <- value`. I recommend that you should make sure that length(value) is the same as length(x[i]), and that i is unique.

```{r}
x <- 1:5
x[c(1, 2)] <- c(101, 102)
x
```

You can use `x[[i]] <- NULL` to delete an element of a list; or use `x[[i]] <- list(NULL)` to replace an element with a literal `NULL` value.

## Subsetting applications

### Lookup tables (character subsetting)

```{r}
x <- c("m", "f", "u", "f", "f", "m", "m")
lookup <- c(m = "Male", f = "Female")
lookup[x]
unname(lookup[x]) ## if you don’t want names in the result
```

### Matching and merging by hand (integer subsetting)

>You can also have more complicated lookup tables with multiple columns of information. For example, suppose we have a vector of integer grades, and a table that describes their properties:

```{r}
grades <- c(1, 2, 2, 3, 1)

info <- tibble::tibble(
  grade = 3:1,
  desc = c("Excellent", "Good", "Poor"),
  fail = c(FALSE, FALSE, TRUE)
)

```

>Then, let’s say we want to duplicate the info table so that we have a row for each value in grades. An elegant way to do this is by combining `match()` and integer subsetting (`match(needles, haystack)` returns the position where each `needle` is found in the `haystack`).

```{r}
id <- match(grades, info$grade) 
id
info[id, ] 
```

>Note that `match()` returns a vector of the positions of (first) matches of its first argument in its second.

### Random samples and bootstraps (integer subsetting)

>You can use integer indices to randomly sample or bootstrap a vector or data frame. Just use sample(n) to generate a random permutation of 1:n, and then use the results to subset the values:

```{r}
df <- head(mtcars, n = 5) %>% tibble::as_tibble(rownames = "id")
df[sample(nrow(df), 100, replace = TRUE), ]
```

### Ordering (integer subsetting)

>`order()` takes a vector as its input and returns an integer vector describing how to order the subsetted vector. 

```{r}
x <- c("b", "c", "a")
order(x)
x[order(x)]
```

>To break ties, you can supply additional variables to `order()`. You can also change the order from ascending to descending by using `decreasing = TRUE`. By default, any missing values will be put at the end of the vector; however, you can remove them with `na.last = NA` or put them at the front with `na.last = FALSE`.

```{r}
df2 <- df[sample(nrow(df)), sample(ncol(df))] ## randomly reorder df
df2[order(df2[[1]]), ]                        ## reorder rows according to first column
df2[ , order(names(df2))]                     ## reorder rows according to first column
```

>You can sort vectors directly with `sort()`, or similarly `dplyr::arrange()`, to sort a data frame.

### Expanding aggregated counts (integer subsetting)

>Sometimes you get a data frame where identical rows have been collapsed into one and a count column has been added. `rep()` and integer subsetting make it easy to uncollapse, because we can take advantage of vectorisation: `rep(x, y)` repeats `x[i] y[i]` times.

```{r}
df <- tibble::tibble(x = c(2, 4, 1), y = c(9, 11, 6), n = c(3, 5, 1))
str(df)
rep(1:nrow(df), df$n)
df[rep(1:nrow(df), df$n), ]
```

### Removing columns from data frames (character)

>There are two ways to remove columns from a data frame. You can set individual columns to `NULL`:

```{r}
df <- data.frame(x = 1:3, y = 3:1, z = letters[1:3])
df$z <- NULL
```

>Or you can subset to return only the columns you want:

```{r}
df <- tibble::tibble(x = 1:3, y = 3:1, z = letters[1:3])
df[c("x", "y")]

## use set operations when you only know the columns you don’t want
df[setdiff(names(df), "x")]
```

### Selecting rows based on a condition (logical subsetting)

>Because logical subsetting allows you to easily combine conditions from multiple columns, it’s probably the most commonly used technique for extracting rows out of a data frame.

```{r}
mtcars[mtcars$gear == 5, ]
mtcars[mtcars$gear == 5 & mtcars$cyl == 4, ]
```

<blockquote>
Remember to use the vector boolean operators `&` and `|`, not the short-circuiting scalar operators `&&` and `||`, which are more useful inside if statements. And don’t forget De Morgan’s laws, which can be useful to simplify negations:

- `!(X & Y)` is the same as `!X | !Y`

- `!(X | Y)` is the same as `!X & !Y`
</blockquote>

### `which()`

___Boolean algebra versus sets (logical and integer)___

<blockquote>
It’s useful to be aware of the natural equivalence between set operations (integer subsetting) and Boolean algebra (logical subsetting). Using set operations is more effective when:

You want to find the first (or last) `TRUE`.

You have very few `TRUE`s and very many `FALSE`s; a set representation may be faster and require less storage.

`which()` allows you to convert a Boolean representation to an integer representation.
</blockquote>

```{r}
x <- sample(8) < 4
x
which(x)
```

>There’s no reverse operation in base R but we can easily create one:

```{r}
unwhich <- function(x, n) {
  out <- rep_len(FALSE, length.out = n)
  out[x] <- TRUE
  return(out)
}
unwhich(which(x), 8)
```

<blockquote>
When first learning subsetting, a common mistake is to use `x[which(y)]` instead of `x[y]`. Here the `which()` achieves nothing: it switches from logical to integer subsetting but the result is exactly the same. In more general cases, there are two important differences.

- When the logical vector contains `NA`, logical subsetting replaces these values with `NA` while `which()` simply drops these values. It’s not uncommon to use `which()` for this side-effect, but I don’t recommend it: nothing about the name "which" implies the removal of missing values.

- `x[-which(y)]` is __not__ equivalent to `x[!y]`: if `y` is all `FALSE`, `which(y)` will be `integer(0)` and `-integer(0)` is still `integer(0)`, so you’ll get no values, instead of all values.

In general, avoid switching from logical to integer subsetting unless you want, for example, the first or last `TRUE` value.
</blockquote>

>Exercise. _How would you randomly permute the columns of a data frame? (This is an important technique in random forests.) Can you simultaneously permute the rows and columns in one step?_

```{r}
df <- head(mtcars, 10)
df[sample(nrow(df)), sample(ncol(df))]
```

## Control Flow

<blockquote>
-__Choices__, like `if` statements and `switch()` calls, allow you to run different code depending on the input. 

-__Loops__, like `for` and `while`, allow you to repeatedly run code, typically with changing options.
</blockquote>

___Choices___

```{r, eval=FALSE}
# The basic form of an "if" statement in R
if (condition) true_action
if (condition) true_action else false_action
```

`if` statements also return values, which in turn can be used for assignments.

```{r}
x <- if (TRUE) 1; x
x <- if (FALSE) 1; x ## invisibly returns a NULL
x <- if (FALSE) 1 else 2; x
```

>The `condition` should evaluate to a single `TRUE` or `FALSE`. Most other inputs will generate an error:

```{r, error=TRUE}
if ("x") 1
if (logical()) 1
if (NA) 1
```

>The exception is a logical vector of length greater than 1, which generates a warning:

```{r}
if (c(TRUE, FALSE)) 1
```

>In R 3.5.0 and greater, thanks to [Henrik Bengtsson](https://github.com/HenrikBengtsson/Wishlist-for-R/issues/38), you can turn this into an error by setting an environment variable:

```{r, error=TRUE}
Sys.setenv("_R_CHECK_LENGTH_1_CONDITION_" = "true")
if (c(TRUE, FALSE)) 1
```

>Handling vectors of logical values is the job of `ifelse()`: a vectorised function with `test`, `yes`, and `no` vectors (that will be recycled to the same length).

```{r}
x <- 1:10
ifelse(x %% 5 == 0, "XXX", as.character(x))
ifelse(x %% 2 == 0, "even", "odd")
```

>Another vectorised equivalent is the more general `dplyr::case_when()`. It uses a special syntax to allow any number of condition-vector pairs:

```{r}
dplyr::case_when(
  x %% 3 == 0 & x %% 5 == 0 ~ "fizz buzz", 
  x %% 3 == 0 ~ "fizz",
  x %% 5 == 0 ~ "buzz",
  is.na(x) ~ "[?]",
  TRUE ~ as.character(x)
)
```

>Closely related to `if` is the `switch()` statement. It’s a compact, special purpose equivalent that lets you replace code like:

```{r}
x_option <- function(x) {
  if (x == "a") {
    "option 1"
  } else if (x == "b") {
    "option 2" 
  } else if (x == "c") {
    "option 3"
  } else {
    stop("Invalid `x` value")
  }
}
```

>with the more succint:

```{r}
x_option <- function(x) {
  switch(x,
    "a" = "option 1",
    "b" = "option 2",
    "c" = "option 3",
    stop("Invalid `x` value")
  )
}
```

>The last component of a `switch()` should always throw an error, otherwise unmatched inputs will invisibly return `NULL`.

___Loops___

```{r, eval=FALSE}
# The basic form of a "loop" in R
for (item in vector) perform_action
```

>Note. `for` assigns the item to the current environment, overwriting any existing variable with the same name.

_Two ways to terminate a loop early:_

1. `next` exits the current iteration.

2. `break` exits the entire loop.

```{r}
for (i in 1:10) {
  if (i < 3) next

  print(i)
  
  if (i >= 5) break
}
```

_Three common pitfalls of `for` loops_

1. If you’re generating data, make sure to preallocate the output container. Otherwise the loop will be very slow (see copy-on-modify semantics).

    ```{r}
    x <- 1:10
    out <- vector("list", length(x))
    for (i in 1:length(out)) out[[i]] <- rnorm(10, x[[i]])
    ```

2. Beware of iterating over `1:length(x)`, which will fail in unhelpful ways if `x` has length 0.

    ```{r, error=TRUE}
    x <- numeric()
    out <- vector("list", length(x))
    for (i in 1:length(out)) out[[i]] <- rnorm(10, x[[i]])
    ```

3. Loops typically strip the attributes of S3 vectors.

```{r}
xs <- as.Date(c("2020-01-01", "2010-01-01"))
for (k in xs) print(k)  ## no longer a date
for (k in seq_along(xs)) print(xs[[k]])
```

We use `while` and `repeat` when we need to use loops, but we don't know in advance the set of values that we want to iterate over.

>You can rewrite any `for` loop to use `while` instead, and you can rewrite any `while` loop to use `repeat`, but the converses are not true. That means `while` is more flexible than `for`, and `repeat` is more flexible than `while.` It’s good practice, however, to use the least-flexible solution to a problem, so you should use `for` wherever possible.

- `while(condition) action`: performs `action` while `condition` is `TRUE`.

- `repeat(action)`: repeats `action` forever (i.e. until it encounters `break`).

    Note that R doesn't have the common `do {action} while (condition)` syntax found in other languages.

>Generally speaking you shouldn’t need to use for loops for data analysis tasks, as `map()` and `apply()` already provide less flexible solutions to most problems.

## Functions

### Fundamentals

Two important ideas:

<blockquote>
1. Functions are objects, just as vectors are objects.

2. Functions can be broken down into three components: arguments, body, and environment.

    There are exceptions to every rule, and in this case, there is a small selection of "primitive" base functions that are implemented purely in C.
</blockquote>

The three parts of any function can be accessed with `formals()`, `body()`, and `environment()`.

```{r}
add <- function(x, y) {
  x + y ## this comment is self explanatory
}

formals(add)
body(add)
environment(add)
```

>Like all objects in R, functions can also possess any number of additional `attributes()`. One attribute used by base R is `srcref`, short for source reference. It points to the source code used to create the function. The `srcref` is used for printing because, unlike `body()`, it contains code comments and other formatting.

```{r}
attributes(add)
```

So-called _primitive functions_, which directly call C code, don't necessarily have three components.

```{r}
## For example
is.primitive(sum)
sum

formals(sum)
body(sum)             
environment(sum)
```

These functions have either type `builtin` or type `special`.

```{r}
typeof(sum)
typeof(`[`)
```

>Primitive functions are only found in the base package. While they have certain performance advantages, this benefit comes at a price: they are harder to write. For this reason, R-core generally avoids creating them unless there is no other option.

R functions are often called ["first-class functions"](https://en.wikipedia.org/wiki/First-class_function).


>Unlike in many other languages, there is no special syntax for defining and naming a function: you simply create a function object (with `function`) and bind it to a name with `<-`

```{r}
f01 <- function(x) {
  sin(1 / x ^ 2)
}
```

If you don't bind a function to a name, you get an _anonymous function_ (equivalent to Python's lambda functions).

```{r}
integrate(function(x) sin(x) ^ 2, lower = 0, upper = 1)
purrr::map_int(mtcars, function(x) length(unique(x)))
```

You can also put functions inside a list:

```{r}
funs <- list(
  half = function(x) x / 2,
  double = function(x) x * 2
)

funs$double(33)
```

Note that we usually call a function by typing its arguments inside parentheses; e.g. `mean(1:10, na.rm = TRUE)`. But sometimes we want to use arguments that are already contained inside a data structure. We can use the `do.call()` function to "invoke" other functions.

For example:

```{r}
args <- list(1:10, na.rm = TRUE)
do.call(mean, args)
purrr::invoke(mean, args) ## purrr equivalent
```

>_Exercise_. This code makes a list of all functions in the base package.

```{r}
objs <- mget(ls("package:base", all = TRUE), inherits = TRUE)
funs <- Filter(is.function, objs)
```

>Use it to answer the following questions:

```{r, message=FALSE}
library(tibble)
library(purrr)

df <- tibble(
  function_name = names(funs),
  num_args = map(funs, formals) %>% map_int(length)
)

# *******************************************
# Which base function has the most arguments?
# *******************************************

df[df$num_args == max(df$num_args), ]

# *******************************************
# How many base functions have no arguments? 
# What’s special about those functions?
# *******************************************

nrow(df[df$num_args == 0, ])

# Note that we are overcounting the number of functions
# without arguments because formals() will return
# NULL for primitive functions.

# *******************************************
# How could you adapt the code to find all 
# primitive functions?
# *******************************************

funs <- Filter(is.primitive, objs)

```

### Composition

There are two ways to compose function calls in base R:

1. Nesting functions.

    >Nesting, `f(g(x))`, is concise, and well suited for short sequences. But longer sequences are hard to read because they are read inside out and right to left.

2. Saving intermediate results as variables.

    >Intermediate objects, `y <- f(x); g(y)`, requires you to name intermediate objects. This is a strength when objects are important, but a weakness when values are truly intermediate.

Additionally, the [__magrittr__](https://magrittr.tidyverse.org/) package provides a third option.

3. The pipe operator.

****

_Example. Calculating the standard deviation of a numeric vector._

```{r}
square <- function(x) x^2
deviation <- function(x) x - mean(x)
x <- runif(100)

# ****************************
# 1. Nesting calls
# ****************************

sqrt(mean(square(deviation(x))))

# ****************************
# 2. Saving intermediate results
# ****************************

out <- deviation(x)
out <- square(out)
out <- mean(out)
out <- sqrt(out)
out

# ****************************
# 3. %>% %>% %>% %>% %>% %>% %>% 
# ****************************

x %>% 
  deviation() %>% 
  square() %>% 
  mean() %>% 
  sqrt()
```

>The pipe allows you to focus on the high-level composition of functions rather than the low-level flow of data; the focus is on what’s being done (the _verbs_), rather than on what’s being modified (the _nouns_). This style is common in Haskell and F#, the main inspiration for magrittr, and is the default style in stack based programming languages like Forth and Factor.

>Piping, `x %>% f() %>% g()`, allows you to read code in straightforward left-to-right fashion and doesn’t require you to name intermediate objects. But you can only use it with linear sequences of transformations of a single object. It also requires an additional third party package and assumes that the reader understands piping.

### Lexical scoping

Scoping is the act of finding the _value_ associated with a _name_. Experienced R users find all of this very intuitive, but new users won't necessarily think the same way.

```{r}
x <- 10
g01 <- function() {
  x <- 20
  x
}

g01()
x
```

>R uses __lexical scoping__: it looks up the values of names based on how a function is defined, not how it is called. "Lexical" here is [...] a technical CS term that tells us that the scoping rules use a parse-time, rather than a run-time structure.

There are four main rules in R's lexical scoping:

1. __Name masking__. Names defined inside a function mask names defined outside a function. And if a name isn't defined inside a function, R looks one level up.

    ```{r}
    x <- 2
    
    g03 <- function() {
      y <- 1
      c(x, y)
    }
    
    g03()
    x <- 9
    g03()
    ```

    >The same rules apply if a function is defined inside another function. First, R looks inside the current function. Then, it looks where that function was defined (and so on, all the way up to the global environment). Finally, it looks in other loaded packages.

2. __Functions versus variables__. Name masking also applies when applied to functions; after all, they're just ordinary R objects. However, there is a subtle distinction. 

    >When you use a name in a function call, R ignores non-function objects when looking for that value.
    
    ```{r}
    a <- function(x) x + 100
    b <- function() {
      a <- 10
      a(a) ## R takes the "left a" from outside the function
    }      ## environment, and the "inside a" one from within.
    b()
    ```

3. __A fresh start__. Every time a function is called, a new environment is created to host its execution. In other words, is "invocation" is completely independent of each other.


4. __Dynamic lookup__. Lexical scoping determines _where_, but not _when_ to look for values. 

    >R looks for values when the function is run, not when the function is created. Together, these two properties tell us that the output of a function can differ depending on the objects outside the function’s environment.
    
    This means that
    
    >If you make a spelling mistake in your code, you won’t get an error message when you create the function. And depending on the variables defined in the global environment, you might not even get an error message when you run the function.
    
```{r}
# Use the following to find all unbound symbols (external 
# dependencies) within a function:
codetools::findGlobals(g03)
```

>R relies on lexical scoping to find __everything__, from the obvious, like `mean()`, to the less obvious, like `+` or even `{`. This gives R’s scoping rules a rather beautiful simplicity.

### Lazy evaluation

In R, function arguments are only evaluated _if_ accessed. This is also known as _lazy evaluation_.

```{r}
h01 <- function(x) 10
h01(asdASDFfasdfASDFawef) ## no error because asdASDFfasdfASDFawef is never used
```

Lazy evaluation is powered by a data structure called a __promise__ (or a [_thunk_](https://en.wikipedia.org/wiki/Thunk)). 

A promise has three components:

1. An _expression_ (e.g. `x + y`) which gives rise to the delayed computation.

2. An _environment_ where the expression should be evaluated (i.e. the environment where the function is called). 

3. A _value_, which is computed and cached the first time a promise is accessed when the expression is evaluated in the specified environment. _This ensures that the promise is evaluated at most once._

>You cannot manipulate promises with R code. Promises are like a quantum state: any attempt to inspect them with R code will force an immediate evaluation, making the promise disappear.

Note. An exception to this behavior is provided by the "quosure" object in the [__`rlang`__](https://rlang.r-lib.org/) package.

Lazy evaluation allows for default values to be defined in terms of other arguments, or even in terms of variables defined inside the function. 

```{r}
h04 <- function(x = 1, y = x * 2, z = a + b) {
  a <- 10; b <- 100 ## not recommended!!!
  c(x, y, z)
}

h04()
```

```{r}
ls()
```

>The evaluation environment is slightly different for default and user supplied arguments, as default arguments are evaluated inside the function. This means that seemingly identical calls can yield different results. It’s easiest to see this with an extreme example:

```{r}
h05 <- function(x = ls()) {
  a <- 1
  x
}

# ls() evaluated inside h05:
h05()
# ls() evaluated in global environment:
h05(x = ls())
```

The `missing()` function will help you determine if an argument's value comes from the user or from a default.

```{r}
h06 <- function(x = 10) list(missing(x), x)
str(h06())
str(h06(20))
```

This special function is behind `sample()`'s erratic behavior.

```{r}
formals(sample)
body(sample)
```

```{r}
sample(5)
sample(5, size = 2)
```

### `...` (dot-dot-dot)

Functions with `...` as an argument can take any number of additional arguments. You can also use `...` to pass those additional arguments to another function. In some programming languages, these are known as [_variadic functions_](https://en.wikipedia.org/wiki/Variadic_function) (i.e. they accept a variable number of arguments).

For example:

```{r}
i01 <- function(y, z) {
  list(y = y, z = z)
}

i02 <- function(x, ...) {
  i01(...)
}

str(i02(x = fdsaasdf, y = 2, z = 3))
```

Using `list(...)` inside a function will evaluate the dot-dot-dot arguments and store them in a list.

```{r}
i04 <- function(x, ...) list(...)
str(i04(a = 1:5, b = "arg", c = 9, 10))
```

Two primary uses of dot-dot-dot:

1. Passing additional arguments to a function inside a function. 

```{r}
# lapply() uses ... to pass na.rm to the mean() function
x <- list(c(1, 3, NA), c(4, NA, 6))
str(lapply(x, mean, na.rm = TRUE))
```

2. Generic functions (e.g. `print`, `summary`) need some way to allow methods to take arbitrary arguments; in other words, `...` allows individual methods to have different arguments.

There is one big downside to dot-dot-dot. 

>A misspelled argument will not raise an error. This makes it easy for typos to go unnoticed.

```{r}
## na_rm is a typo
sum(1, 2, NA, na_rm = TRUE)
sum(1, 2, na_rm = TRUE)
```

### Exiting

Most functions exit when they return a value (success) or when they throw an error (failure).

EXIT HANDLERS


___Returns___

```{r}
j01 <- function() 10            ## implicit
j01() 

j02 <- function() return(10)    ## explicit
j02()
```

You can prevent automatic printing by applying `invisible()` to the last value.

```{r}
j03 <- function() invisible(10)    ## implicit and invisible
j03()
```

> To verify that this value does indeed exist, you can explicitly print it or [wrap it in parentheses](https://yihui.name/en/2017/06/top-level-r-expressions/)

```{r}
print(j03())
(j03())
```

>Alternatively, you can use `withVisible()` to return the value and a visibility flag:

```{r}
withVisible(j03())
```

The most common function that returns invisibly is the assignment operator `<-`.

```{r}
a <- 2
(a <- 2)
```

>In general, any function called primarily for a side effect (like `<-`, `print()`, or `plot()`) should return an invisible value (typically the value of the first argument).

___Errors___

If, for some reason, a function cannot complete its assigned task, it should throw an error with `stop()`, which immediately terminates the execution of the function.

```{r, error=TRUE}
j04 <- function() {
  stop("I'm an error")
  return(10)
}
j04()
```

An error should indicate that something has gone wrong, and force the user to deal with the problem.

Sometimes a function will need to make temporary changes to the global state, and we therefore need a painless way to ensure that these changes are undone regardless of how a function exits. To achieve this, we use `on.exit()` to set up an __exit handler__. _Any  exit handler is run independently of whether the function exits normally or with an error._

>Coupled with lazy evaluation, this creates a very useful pattern for running a block of code in an altered environment:

```{r}
with_dir <- function(dir, code) {
  old <- setwd(dir)
  on.exit(setwd(old), add = TRUE)

  force(code)
}

with_dir("../..", getwd())
getwd()
```

>The use of `force()` isn’t strictly necessary here as simply referring to code will force its evaluation. However, using `force()` makes it very clear that we are deliberately forcing the execution.

### Function forms 

>While everything that happens in R is a result of a function call, not all calls look the same.

Four types of functions:

1. __Prefix__: functions whose name come before the arguments, like `f(a, b, c)`. 

2. __Infix__: functions whose name comes in between the arguments, like `x + y`. These are usually used for mathematical operators or user-defined functions that begin and end with `%`, like the pipe.

3. __Replacement__: functions that replace values by assignment, like `names(df) <- c("a", "b", "c")`. They look like prefix functions.

4. __Special__: functions like `[[`, `if`, and `for.` They don’t have a consistent structure.

All four forms can be rewritten in prefix form.

```{r}
1 + 2                             ## infix
`+`(1, 2)                         ## prefix

df <- data.frame(x = 1:10, y = 21:30, z = 31:40)
names(df) <- c("x", "y", "z")     ## replacement
`names<-`(df, c("x", "y", "z"))   ## prefix

for (i in 1:5) cat(i)             ## special
`for`(i, 1:5, cat(i))             ## prefix
```

Pretty much every operation in R can be _called_ as a prefix function. This means that we can override the behavior of regular functions.

```{r}
## This example introduces a bug in the "(" function 20% of the time.
`(` <- function(x) {
  if (is.numeric(1) & runif(1) < 0.2) {
    x + 1
  } else {
    x
  }
}

replicate(30, (1 + 1))

rm("(")
```

****

___More details___

<blockquote>
The __prefix form__ is the most common form in R code, and indeed in the majority of programming languages. Prefix calls in R are a little special because you can specify arguments in three ways:

- By _position_, like `help(mean)`.
- Using _partial matching_, like `help(top = mean)`.
- By _name_, like `help(topic = mean)`.

As illustrated by the following chunk, arguments are matched by exact name, then with unique prefixes, and finally by position.
</blockquote>

```{r, error=TRUE}
k01 <- function(abcdef, bcde1, bcde2) {
  list(a = abcdef, b1 = bcde1, b2 = bcde2)
}

str(k01(1, 2, 3))             ## by position
str(k01(1, 2, abcdef = 3))    ## by name and position
str(k01(1, 2, a = 3))         ## by partial matching and position

# This won't work when partial matching is ambiguous
k01(1, 2, b = 3)
```

>In general, use positional matching only for the first one or two arguments; they will be the most commonly used, and most readers will know what they are. Avoid using positional matching for less commonly used arguments, and never use partial matching. Unfortunately you can’t disable partial matching, but you can turn it into a warning with the `warnPartialMatchArgs` option:

```{r}
options(warnPartialMatchArgs = TRUE)
invisible(k01(1, 2, a = 3))
```

```{r, echo=FALSE}
options(warnPartialMatchArgs = FALSE)
```


>__Infix functions__ get their name from the fact the function name comes inbetween its arguments, and hence have two arguments. R comes with a number of built-in infix operators: `:`, `::`, `:::`, `$`, `@`, `^`, `*`, `/`, `+`, `-`, `>`, `>=`, `<`, `<=`, `==`, `!=`, `!`, `&`, `&&`, `|`, `||`, `~`, `<-`, and `<<-`. You can also create your own infix functions that start and end with `%`. Base R uses this pattern to define `%%`, `%*%`, `%/%`, `%in%`, `%o%`, and `%x%`.

_Example. Defining an infix function that concatenates strings._

```{r}
`%+%` <- function(a, b) paste(a, b)
"new" %+% "string"
```

>R's default precedence rules mean that infix operators are composed left to right:

```{r}
`%-%` <- function(a, b) paste0("(", a, " %-% ", b, ")")
"a" %-% "b" %-% "c"
```

>There are two special infix functions that can be called with a single argument: `+` and `-`.

```{r}
-1; +10
```

>__Replacement functions__ act like they modify their arguments in place, and have the special name `xxx<-`. They must have arguments named `x` and `value`, and must return the modified object. For example, the following function modifies the second element of a vector:

```{r}
`second<-` <- function(x, value) { 
  x[2] <- value
  return(x) 
}

x <- 1:5
second(x) <- 99L  ## function call is on the left side of <-
x
```

>If your replacement function needs additional arguments, place them between `x` and `value`, and call the replacement function with additional arguments on the left:

```{r}
`modify<-` <- function(x, position, value) {
  x[position] <- value
  x
}
modify(x, 1) <- 10
```

Note that, due to R's copy-on-modify semantics, these functions don't actually modify their arguments in place: they create a modified copy.

```{r}
obj_addr(x)
modify(x, 1) <- 5L
obj_addr(x)
```

Finally, we have __special functions__, that can also be rewritten in prefix form.

Parentheses: 

- `(x)` becomes ``` `(`(x) ```
- `{x}` becomes ``` `{`(x) ```

Subsetting operators:

- `x[i]` becomes ``` `[`(x, i) ```

- `x[[i]]` becomes ``` `[[`(x, i) ```

Control flow:

- `if (cond) true` becomes ``` `if`(cond, true) ```

- `if (cond) true else false` becomes ``` `if`(cond, true, false) ```

- `for(var in seq) action` becomes ``` `for`(var, seq, action) ```

- `while(cond) action` becomes ``` `while`(cond, action) ```

- `repeat expr` becomes  ``` `repeat`(expr) ```

- `next` becomes ``` `next`() ```

- `break` becomes ``` `break`() ```

>Finally, the most complex is the `function` function:

- `function(arg1, arg2) {body}` becomes ``` `function`(alist(arg1, arg2), body, env) ```

## Environments

>The environment is the data structure that powers scoping.

>Understanding environments is not necessary for day-to-day use of R. But they are important to understand because they power many important R features like lexical scoping, namespaces, and R6 classes, and interact with evaluation to give you powerful tools for making domain specific languages, like dplyr and ggplot2.

>This chapter will use [__`rlang`__](https://rlang.r-lib.org/) functions for working with environments.

```{r}
library(rlang)
```

>The `env_` functions in rlang are designed to work with the pipe: all take an environment as the first argument, and many also return an environment. 

### Basics

To create an environment, we use `rlang::env()`. 

>The job of an environment is to associate, or __bind__, a set of names to a set of values. You can think of an environment as a bag of names, with no implied order (i.e. it doesn’t make sense to ask which is the first element in an environment). For that reason, we’ll draw the environment as so:

```{r}
e1 <- env(
  a = FALSE,
  b = "a",
  c = 2.3,
  d = 1:3,
)
```


```{r, echo=FALSE, out.width="180px"}
knitr::include_graphics(
"https://d33wubrfki0l68.cloudfront.net/f5dbd02f5235283e78decdd4f18692b40f1ddf42/c5683/diagrams/environments/bindings.png"
)
```

In other words, environments in R are similar to hashmaps (or "dictionaries" in Python). Environments have __reference semantics__.

>unlike most R objects, when you modify them, you modify them in place, and don’t create a copy. One important implication is that environments can contain themselves.

```{r}
e1$d <- e1
```

```{r, echo=FALSE, out.width="180px"}
knitr::include_graphics(
"https://d33wubrfki0l68.cloudfront.net/0d41862821d3226c38b73f78a530117349b7344a/abb88/diagrams/environments/loop.png"
)
```

If you try to print an environment, you won't see any useful information (just the memory address).

```{r}
print(e1)
```

Instead, we use `rlang::env_print()` to see more information.

```{r}
env_print(e1)
```

And we use `rlang::env_names()` to get a character vector that gives the current bindings.

```{r}
env_names(e1)  ## equivalent to names(e1) as of R 3.2.0
```

>The __current environment__, or `current_env()` is the environment in which code is currently executing. When you’re experimenting interactively, that’s usually the global environment, or `global_env()`. The global environment is sometimes called your "workspace", as it’s where all interactive (i.e. outside of a function) computation takes place.

>To compare environments, you need to use `identical()` and not `==`. This is because `==` is a vectorised operator, and environments are _not_ vectors.

```{r, error=TRUE}
current_env()
identical(global_env(), current_env())
global_env() == current_env()
```

>Every environment has a __parent__, another environment. In diagrams, the parent is shown as a small pale blue circle and arrow that points to another environment. The parent is what’s used to implement lexical scoping: if a name is not found in an environment, then R will look in its parent (and so on). You can set the parent environment by supplying an unnamed argument to `env()`. If you don’t supply it, it defaults to the current environment. In the code below, `e2a` is the parent of `e2b`.

```{r}
e2a <- env(d = 4, e = 5)
e2b <- env(e2a, a = 1, b = 2, c = 3)
```

```{r, echo=FALSE, out.width="180px"}
knitr::include_graphics(
"https://d33wubrfki0l68.cloudfront.net/336e61bf494a6424484b8b2685a440a7db1566bf/59bce/diagrams/environments/parents.png"
)
```

In these diagrams, every pale blue dot indicates the existence of a parent environment.

```{r}
env_parent(e2b)
env_parent(e2a)
```



### Computing with environments

### Special environments

### Call stacks

### Environments as data structures

## Conditions










